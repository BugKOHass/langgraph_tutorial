{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Nice to meet\n",
      "Assistant: I don't know\n",
      "Assistant: I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Building a basic chatbot\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from IPython.display import Image, display\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "\n",
    "secrets = Config(RepositoryEnv(\".env\"))\n",
    "\n",
    "GROQ_API_KEY = secrets(\"GROQ_API_KEY\")\n",
    "\n",
    "groq_api_key = GROQ_API_KEY\n",
    "\n",
    "# * The class \"State\" is a dict based on TypedDict; this means that we can specify\n",
    "# which keys and what \"type\" of values it can have. We have defined it to have only \n",
    "# one key i.e. \"messages\" and the type of its value to be a list.\n",
    "# * The `add_messages` function in the annotation defines how this state should be updated:\n",
    "# we can only append messages to the list, not overwrite them.\n",
    "# * However, in our current implementation, we are not saving the state anywhere; when we\n",
    "# execute graph.stream(...), it initiates the graph with a new state.\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    groq_api_key = groq_api_key\n",
    ")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    # print(state)\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# * The first argument is the unique node name\n",
    "# * The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "\n",
    "\n",
    "# * In this case, we have only one node - hence, we would get only one output / event from graph.stream;\n",
    "# but if we had multiple nodes, we would get multiple outputs / events i.e. one output for each node.\n",
    "# * \"event\" is a dictionary containing the output of a node; its key is the name of that node e.g. \"chatbot\" and\n",
    "# its values are the list of dictionaries returned by the chatbot function.\n",
    "# * Our \"chatbot\" node is returning only a single dictionary, hence the list \"event.values()\" contains a\n",
    "# single dictionary: {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "# * In the dictionary {\"messages\": [llm.invoke(state[\"messages\"])]}, the value stored against the \"messages\" key \n",
    "# is a list; in our case, we can see that this list contains a single item only i.e. the response of the llm.\n",
    "def stream_graph_updates(user_input: str):\n",
    "    system_prompt = {\"role\": \"system\", \"content\": \"You respond in three words only.\"}\n",
    "    user_prompt = {\"role\": \"user\", \"content\": user_input}\n",
    "    for event in graph.stream({\"messages\": [system_prompt, user_prompt]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        # user_input = input(\"User: \")\n",
    "        # if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        #     print(\"Goodbye!\")\n",
    "        #     break\n",
    "        if i==0: user_input = \"My name is Hassaan.\"\n",
    "        if i==1: user_input = \"What's my name?\"\n",
    "        if i==2: user_input = \"What's the date today?\" # llama3.3-70b hosted on groq fetches the actual date!\n",
    "        stream_graph_updates(user_input)\n",
    "        if i==2: break\n",
    "        i += 1\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_624e', 'function': {'arguments': '{\"query\": \"current date\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 288, 'total_tokens': 307, 'completion_time': 0.069090909, 'prompt_time': 0.025676741, 'queue_time': 0.24843861699999997, 'total_time': 0.09476765}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c4760ee73b', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1d1138a1-5f57-4c95-9f24-a829e7079cf8-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current date'}, 'id': 'call_624e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 288, 'output_tokens': 19, 'total_tokens': 307})]}}\n",
      "Assistant: \n",
      "{'tools': {'messages': [ToolMessage(content='[{\"title\": \"What Is Today\\'s Date? - Inch Calculator\", \"url\": \"https://www.inchcalculator.com/what-is-todays-date/\", \"content\": \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\\\nFull bio\\\\nAre you trying to figure out what the current date is?\\\\n \\\\nToday\\'s Date Is:\\\\nSaturday, February 8, 2025\\\\nAdd this to your site\\\\nToday, February 8th, is day 39 of 365 total days in 2025.\\\\nWhat is Today\\'s Date in Numbers?\\\\nToday\\'s date in numbers is:\\\\n\\\\nMM-DD-YYYY: 02-08-2025\\\\nDD-MM-YYYY: 08-02-2025\\\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today\\'s date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\\\n| 28 | 29 | 30 | 31 |  |  |  |\\\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\\\nHow To Calculate Today\\'s Date Using Excel or Sheets\\\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\\\n\\\\\\\\=TODAY()\", \"score\": 0.6509003977124183}, {\"title\": \"Today\\'s Date | Current date now - RapidTables.com\", \"url\": \"https://www.rapidtables.com/tools/todays-date.html\", \"content\": \"Today\\'s Date | Current date now \\\\ud83d\\\\udcc5\\\\nRapidTables\\\\n Search  Share\\\\nHome\\\\u203aTools\\\\u203aCurrent date now\\\\nToday\\'s Date Now\\\\nToday\\'s current date and time with time zone and date picker:\\\\nSelect locale\\\\nThis page includes the following information:\\\\n\\\\nToday\\'s date: day of week, month, day, year.\\\\nCurrent time: hours, minutes, seconds.\\\\nTime zone with location and GMT offset.\\\\nDate picker of current date.\\\\nCalendar chart.\\\\n\\\\n\\\\n\\\\nCurrent Time\\\\nOnline Clock\\\\nCalendar\\\\nCountdown Timer\\\\nStopwatch\", \"score\": 0.6247950602941177}]', name='tavily_search_results_json', id='acfa0e54-819b-4dc7-a99f-0f94c0d76cba', tool_call_id='call_624e')]}}\n",
      "Assistant: [{\"title\": \"What Is Today's Date? - Inch Calculator\", \"url\": \"https://www.inchcalculator.com/what-is-todays-date/\", \"content\": \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\nFull bio\\nAre you trying to figure out what the current date is?\\n \\nToday's Date Is:\\nSaturday, February 8, 2025\\nAdd this to your site\\nToday, February 8th, is day 39 of 365 total days in 2025.\\nWhat is Today's Date in Numbers?\\nToday's date in numbers is:\\n\\nMM-DD-YYYY: 02-08-2025\\nDD-MM-YYYY: 08-02-2025\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today's date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\n| 28 | 29 | 30 | 31 |  |  |  |\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\nHow To Calculate Today's Date Using Excel or Sheets\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\n\\\\=TODAY()\", \"score\": 0.6509003977124183}, {\"title\": \"Today's Date | Current date now - RapidTables.com\", \"url\": \"https://www.rapidtables.com/tools/todays-date.html\", \"content\": \"Today's Date | Current date now \\ud83d\\udcc5\\nRapidTables\\n Search  Share\\nHome\\u203aTools\\u203aCurrent date now\\nToday's Date Now\\nToday's current date and time with time zone and date picker:\\nSelect locale\\nThis page includes the following information:\\n\\nToday's date: day of week, month, day, year.\\nCurrent time: hours, minutes, seconds.\\nTime zone with location and GMT offset.\\nDate picker of current date.\\nCalendar chart.\\n\\n\\n\\nCurrent Time\\nOnline Clock\\nCalendar\\nCountdown Timer\\nStopwatch\", \"score\": 0.6247950602941177}]\n",
      "{'chatbot': {'messages': [AIMessage(content='The current date is Saturday, February 8, 2025.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 863, 'total_tokens': 878, 'completion_time': 0.054545455, 'prompt_time': 0.063001713, 'queue_time': 0.24852204499999997, 'total_time': 0.117547168}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_90c1d253ff', 'finish_reason': 'stop', 'logprobs': None}, id='run-7af6091a-0a6b-43e0-9689-b8398b99a8c3-0', usage_metadata={'input_tokens': 863, 'output_tokens': 15, 'total_tokens': 878})]}}\n",
      "Assistant: The current date is Saturday, February 8, 2025.\n"
     ]
    }
   ],
   "source": [
    "# Part 2(a) - using custom BasicToolNode and route_tools (instead of the prebuilt ToolNode and tools_condition, respectively) - for learning purposes\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import ToolMessage\n",
    "import os\n",
    "import json\n",
    "\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "\n",
    "secrets = Config(RepositoryEnv(\".env\"))\n",
    "\n",
    "TAVILY_API_KEY = secrets(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = secrets(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "groq_api_key = GROQ_API_KEY\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    groq_api_key = groq_api_key\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        \n",
    "        # This creates a dictionary containing each tool name as the key and the tool itself as the value against that key\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # := is the walrus operator\n",
    "        # It assigns the value inputs.get(\"messages\", []) to \"messages\" variable inside the \"if\" condition.\n",
    "        # If \"messages\" variable does not come out to be an empty list, the latest message (i.e. AIMessage) is assigned to\n",
    "        # \"message\" variable. The \"chatbot\" we defined above outputs only a single msg i.e. the response of the LLM (llm_with_tools).\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        # The LLM's tool-calling support and binding the llm to the tools (llm.bind_tools - see above) results in tool_calls being added to the AIMEssage.\n",
    "        # Each tool call contains the name of the tool that the LLM wants to call, the input (\"args\") to be fed to that tool as well as an ID for that tool call.\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            # For each tool call, we get the output of the relevant tool and append it to the \"outputs\" list.\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "# We initialize the BasicToolNode class using the list of tools (see __init__ method of the class BasicToolNode)\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Recall that edges route the control flow from one node to the next. Conditional edges usually contain \"if\" statements to \n",
    "# route to different nodes depending on the current graph state. These functions receive the current graph state and return \n",
    "# a string or list of strings indicating which node(s) to call next. In our case, we are returning just a string i.e. either\n",
    "# \"tools\" or END.\n",
    "# Below, define a router function called route_tools, that checks for tool_calls in the chatbot's output. Provide this \n",
    "# function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes, \n",
    "# check this function to see where to go next.\n",
    "# The condition will route to tools if tool calls are present and END if not.\n",
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge (add_conditional_edges) to route to the tool node(BasicToolNode) if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # This function gets, as an input, the output of the \"chatbot\" node - which has the same type as the class \"State\".\n",
    "    # The first condition (if isinstance) would have held true if we had defined the chatbot node's output to be a list. \n",
    "    # However, we have defined its output to be a dictionary whose key is \"messages\" and whose value is a list \n",
    "    # containing a single message i.e. the LLM's response.\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# The `route_tools` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node.\n",
    "    # It defaults to the identity function (i.e. value=key), but if we want to use a node named something else apart from \"tools\",\n",
    "    # we can update the value of the dictionary to something else e.g. \"tools\": \"my_tools\".\n",
    "    # NOTE: However, DON'T use the identify function if the key/value are going to be sth other than \"tools\"! That would\n",
    "    # cause the code to silently fail / prevent the generation of graph's image (see code below: display(Image...)).\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception:\n",
    "#     pass\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    # Here, there are two nodes i.e. \"chatbot\" and \"tools\". So, we get the following events:\n",
    "    # - chatbot's call to tools node\n",
    "    # - tools node's output\n",
    "    # - chatbot's response based on tools node's output\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        print(event)\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    if i==0: user_input = \"What's the date today? Find it online.\"\n",
    "    stream_graph_updates(user_input)\n",
    "    if i==0: break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6p94', 'function': {'arguments': '{\"query\": \"current date\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 288, 'total_tokens': 307, 'completion_time': 0.069090909, 'prompt_time': 0.019130655, 'queue_time': 0.24759852, 'total_time': 0.088221564}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_90c1d253ff', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-584c6955-8a7f-4b94-9b1e-c794b2cf0599-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current date'}, 'id': 'call_6p94', 'type': 'tool_call'}], usage_metadata={'input_tokens': 288, 'output_tokens': 19, 'total_tokens': 307})]}}\n",
      "Assistant:  \n",
      "\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"title\": \"What Is Today\\'s Date? - Inch Calculator\", \"url\": \"https://www.inchcalculator.com/what-is-todays-date/\", \"content\": \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\\\nFull bio\\\\nAre you trying to figure out what the current date is?\\\\n \\\\nToday\\'s Date Is:\\\\nSaturday, February 8, 2025\\\\nAdd this to your site\\\\nToday, February 8th, is day 39 of 365 total days in 2025.\\\\nWhat is Today\\'s Date in Numbers?\\\\nToday\\'s date in numbers is:\\\\n\\\\nMM-DD-YYYY: 02-08-2025\\\\nDD-MM-YYYY: 08-02-2025\\\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today\\'s date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\\\n| 28 | 29 | 30 | 31 |  |  |  |\\\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\\\nHow To Calculate Today\\'s Date Using Excel or Sheets\\\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\\\n\\\\\\\\=TODAY()\", \"score\": 0.6509003977124183}, {\"title\": \"Today\\'s Date | Current date now - RapidTables.com\", \"url\": \"https://www.rapidtables.com/tools/todays-date.html\", \"content\": \"Today\\'s Date | Current date now ðŸ“…\\\\nRapidTables\\\\n Search  Share\\\\nHomeâ€ºToolsâ€ºCurrent date now\\\\nToday\\'s Date Now\\\\nToday\\'s current date and time with time zone and date picker:\\\\nSelect locale\\\\nThis page includes the following information:\\\\n\\\\nToday\\'s date: day of week, month, day, year.\\\\nCurrent time: hours, minutes, seconds.\\\\nTime zone with location and GMT offset.\\\\nDate picker of current date.\\\\nCalendar chart.\\\\n\\\\n\\\\n\\\\nCurrent Time\\\\nOnline Clock\\\\nCalendar\\\\nCountdown Timer\\\\nStopwatch\", \"score\": 0.6247950602941177}]', name='tavily_search_results_json', id='d3056ba4-312a-41e0-a73e-d1189b03440e', tool_call_id='call_6p94', artifact={'query': 'current date', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.inchcalculator.com/what-is-todays-date/', 'title': \"What Is Today's Date? - Inch Calculator\", 'content': \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\nFull bio\\nAre you trying to figure out what the current date is?\\n \\nToday's Date Is:\\nSaturday, February 8, 2025\\nAdd this to your site\\nToday, February 8th, is day 39 of 365 total days in 2025.\\nWhat is Today's Date in Numbers?\\nToday's date in numbers is:\\n\\nMM-DD-YYYY: 02-08-2025\\nDD-MM-YYYY: 08-02-2025\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today's date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\n| 28 | 29 | 30 | 31 |  |  |  |\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\nHow To Calculate Today's Date Using Excel or Sheets\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\n\\\\=TODAY()\", 'score': 0.6509003977124183, 'raw_content': None}, {'url': 'https://www.rapidtables.com/tools/todays-date.html', 'title': \"Today's Date | Current date now - RapidTables.com\", 'content': \"Today's Date | Current date now ðŸ“…\\nRapidTables\\n Search  Share\\nHomeâ€ºToolsâ€ºCurrent date now\\nToday's Date Now\\nToday's current date and time with time zone and date picker:\\nSelect locale\\nThis page includes the following information:\\n\\nToday's date: day of week, month, day, year.\\nCurrent time: hours, minutes, seconds.\\nTime zone with location and GMT offset.\\nDate picker of current date.\\nCalendar chart.\\n\\n\\n\\nCurrent Time\\nOnline Clock\\nCalendar\\nCountdown Timer\\nStopwatch\", 'score': 0.6247950602941177, 'raw_content': None}], 'response_time': 1.59})]}}\n",
      "Assistant: [{\"title\": \"What Is Today's Date? - Inch Calculator\", \"url\": \"https://www.inchcalculator.com/what-is-todays-date/\", \"content\": \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\nFull bio\\nAre you trying to figure out what the current date is?\\n \\nToday's Date Is:\\nSaturday, February 8, 2025\\nAdd this to your site\\nToday, February 8th, is day 39 of 365 total days in 2025.\\nWhat is Today's Date in Numbers?\\nToday's date in numbers is:\\n\\nMM-DD-YYYY: 02-08-2025\\nDD-MM-YYYY: 08-02-2025\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today's date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\n| 28 | 29 | 30 | 31 |  |  |  |\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\nHow To Calculate Today's Date Using Excel or Sheets\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\n\\\\=TODAY()\", \"score\": 0.6509003977124183}, {\"title\": \"Today's Date | Current date now - RapidTables.com\", \"url\": \"https://www.rapidtables.com/tools/todays-date.html\", \"content\": \"Today's Date | Current date now ðŸ“…\\nRapidTables\\n Search  Share\\nHomeâ€ºToolsâ€ºCurrent date now\\nToday's Date Now\\nToday's current date and time with time zone and date picker:\\nSelect locale\\nThis page includes the following information:\\n\\nToday's date: day of week, month, day, year.\\nCurrent time: hours, minutes, seconds.\\nTime zone with location and GMT offset.\\nDate picker of current date.\\nCalendar chart.\\n\\n\\n\\nCurrent Time\\nOnline Clock\\nCalendar\\nCountdown Timer\\nStopwatch\", \"score\": 0.6247950602941177}] \n",
      "\n",
      "{'chatbot': {'messages': [AIMessage(content='The current date is Saturday, February 8, 2025.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 855, 'total_tokens': 870, 'completion_time': 0.054545455, 'prompt_time': 0.063064343, 'queue_time': 0.24806474600000003, 'total_time': 0.117609798}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_90c1d253ff', 'finish_reason': 'stop', 'logprobs': None}, id='run-a6d84503-617b-4ba4-bdc9-33d603e3813b-0', usage_metadata={'input_tokens': 855, 'output_tokens': 15, 'total_tokens': 870})]}}\n",
      "Assistant: The current date is Saturday, February 8, 2025. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Part 2(b) - using the prebuilt ToolNode and tools_condition - NOTE: these do some nice things like parallel API execution\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "\n",
    "secrets = Config(RepositoryEnv(\".env\"))\n",
    "\n",
    "TAVILY_API_KEY = secrets(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = secrets(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "groq_api_key = GROQ_API_KEY\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    groq_api_key = groq_api_key\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# The `tools_condition` function directs the control flow towards either the \"tools\" node or END.\n",
    "# Note that tools_condition is a prebuilt function; hence, we are required to use the name \"tools\" for our tools node;\n",
    "# custom name is not allowed.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "# graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\") # serves the same purpose as the above line\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception as e:\n",
    "#     print(f\"error: {str(e)}\")\n",
    "\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        print(event)\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content, \"\\n\")\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    if i==0: user_input = \"What's the date today? Find it online.\"\n",
    "    stream_graph_updates(user_input)\n",
    "    if i==0: break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next node: ()\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Hassaan.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Hassaan, it's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "StateSnapshot(values={'messages': [HumanMessage(content='My name is Hassaan.', additional_kwargs={}, response_metadata={}, id='51fda78a-fa42-4eaa-8eb0-2f5d9301cd39'), AIMessage(content=\"Hello Hassaan, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 284, 'total_tokens': 311, 'completion_time': 0.098181818, 'prompt_time': 0.018730267, 'queue_time': 0.054310313, 'total_time': 0.116912085}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_41c250edc7', 'finish_reason': 'stop', 'logprobs': None}, id='run-a87eb050-b06a-4a6f-afcb-db54da37072f-0', usage_metadata={'input_tokens': 284, 'output_tokens': 27, 'total_tokens': 311})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0072b9-5486-6be8-8001-1e0fb6cb60d9'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content=\"Hello Hassaan, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 284, 'total_tokens': 311, 'completion_time': 0.098181818, 'prompt_time': 0.018730267, 'queue_time': 0.054310313, 'total_time': 0.116912085}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_41c250edc7', 'finish_reason': 'stop', 'logprobs': None}, id='run-a87eb050-b06a-4a6f-afcb-db54da37072f-0', usage_metadata={'input_tokens': 284, 'output_tokens': 27, 'total_tokens': 311})]}}, 'thread_id': '1', 'step': 1, 'parents': {}}, created_at='2025-03-22T14:40:21.802432+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0072b9-4a3e-6b87-8000-302e1876d7d2'}}, tasks=())\n",
      "Next node: ()\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the date today? Find it online\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_a71d)\n",
      " Call ID: call_a71d\n",
      "  Args:\n",
      "    query: current date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"What Is Today's Date? - Inch Calculator\", \"url\": \"https://www.inchcalculator.com/what-is-todays-date/\", \"content\": \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\nFull bio\\nAre you trying to figure out what the current date is?\\n \\nToday's Date Is:\\nSaturday, February 8, 2025\\nAdd this to your site\\nToday, February 8th, is day 39 of 365 total days in 2025.\\nWhat is Today's Date in Numbers?\\nToday's date in numbers is:\\n\\nMM-DD-YYYY: 02-08-2025\\nDD-MM-YYYY: 08-02-2025\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today's date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\n| 28 | 29 | 30 | 31 |  |  |  |\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\nHow To Calculate Today's Date Using Excel or Sheets\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\n\\\\=TODAY()\", \"score\": 0.6517872610119048}, {\"title\": \"Today's Date | Current date now - RapidTables.com\", \"url\": \"https://www.rapidtables.com/tools/todays-date.html\", \"content\": \"Today's Date | Current date now ðŸ“…\\nRapidTables\\n Search  Share\\nHomeâ€ºToolsâ€ºCurrent date now\\nToday's Date Now\\nToday's current date and time with time zone and date picker:\\nSelect locale\\nThis page includes the following information:\\n\\nToday's date: day of week, month, day, year.\\nCurrent time: hours, minutes, seconds.\\nTime zone with location and GMT offset.\\nDate picker of current date.\\nCalendar chart.\\n\\n\\n\\nCurrent Time\\nOnline Clock\\nCalendar\\nCountdown Timer\\nStopwatch\", \"score\": 0.6253473897321429}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current date is Saturday, February 8, 2025.\n",
      "StateSnapshot(values={'messages': [HumanMessage(content='My name is Hassaan.', additional_kwargs={}, response_metadata={}, id='51fda78a-fa42-4eaa-8eb0-2f5d9301cd39'), AIMessage(content=\"Hello Hassaan, it's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 284, 'total_tokens': 311, 'completion_time': 0.098181818, 'prompt_time': 0.018730267, 'queue_time': 0.054310313, 'total_time': 0.116912085}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_41c250edc7', 'finish_reason': 'stop', 'logprobs': None}, id='run-a87eb050-b06a-4a6f-afcb-db54da37072f-0', usage_metadata={'input_tokens': 284, 'output_tokens': 27, 'total_tokens': 311}), HumanMessage(content=\"What's the date today? Find it online\", additional_kwargs={}, response_metadata={}, id='2176a60c-703e-4c65-9522-f03668b5d31b'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_a71d', 'function': {'arguments': '{\"query\": \"current date\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 329, 'total_tokens': 348, 'completion_time': 0.069090909, 'prompt_time': 0.023436396, 'queue_time': 0.053461252, 'total_time': 0.092527305}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_41c250edc7', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea289021-95ba-4e9f-a21a-499106adfa9e-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current date'}, 'id': 'call_a71d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 329, 'output_tokens': 19, 'total_tokens': 348}), ToolMessage(content='[{\"title\": \"What Is Today\\'s Date? - Inch Calculator\", \"url\": \"https://www.inchcalculator.com/what-is-todays-date/\", \"content\": \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\\\nFull bio\\\\nAre you trying to figure out what the current date is?\\\\n \\\\nToday\\'s Date Is:\\\\nSaturday, February 8, 2025\\\\nAdd this to your site\\\\nToday, February 8th, is day 39 of 365 total days in 2025.\\\\nWhat is Today\\'s Date in Numbers?\\\\nToday\\'s date in numbers is:\\\\n\\\\nMM-DD-YYYY: 02-08-2025\\\\nDD-MM-YYYY: 08-02-2025\\\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today\\'s date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\\\n| 28 | 29 | 30 | 31 |  |  |  |\\\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\\\nHow To Calculate Today\\'s Date Using Excel or Sheets\\\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\\\n\\\\\\\\=TODAY()\", \"score\": 0.6517872610119048}, {\"title\": \"Today\\'s Date | Current date now - RapidTables.com\", \"url\": \"https://www.rapidtables.com/tools/todays-date.html\", \"content\": \"Today\\'s Date | Current date now ðŸ“…\\\\nRapidTables\\\\n Search  Share\\\\nHomeâ€ºToolsâ€ºCurrent date now\\\\nToday\\'s Date Now\\\\nToday\\'s current date and time with time zone and date picker:\\\\nSelect locale\\\\nThis page includes the following information:\\\\n\\\\nToday\\'s date: day of week, month, day, year.\\\\nCurrent time: hours, minutes, seconds.\\\\nTime zone with location and GMT offset.\\\\nDate picker of current date.\\\\nCalendar chart.\\\\n\\\\n\\\\n\\\\nCurrent Time\\\\nOnline Clock\\\\nCalendar\\\\nCountdown Timer\\\\nStopwatch\", \"score\": 0.6253473897321429}]', name='tavily_search_results_json', id='565726db-9019-420a-b179-f788fa28b861', tool_call_id='call_a71d', artifact={'query': 'current date', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.inchcalculator.com/what-is-todays-date/', 'title': \"What Is Today's Date? - Inch Calculator\", 'content': \"Ethan has a PhD in astrophysics and is currently a satellite imaging scientist. He specializes in math, science, and astrophysics.\\nFull bio\\nAre you trying to figure out what the current date is?\\n \\nToday's Date Is:\\nSaturday, February 8, 2025\\nAdd this to your site\\nToday, February 8th, is day 39 of 365 total days in 2025.\\nWhat is Today's Date in Numbers?\\nToday's date in numbers is:\\n\\nMM-DD-YYYY: 02-08-2025\\nDD-MM-YYYY: 08-02-2025\\nYYYY-MM-DD: 2025-02-08 [...] Simply enter this formula into any empty cell to get today's date. For instance, if the current date is November 1st, then the result might look like this: [...] | 14 | 15 | 16 | 17 | 18 | 19 | 20 |\\n| 21 | 22 | 23 | 24 | 25 | 26 | 27 |\\n| 28 | 29 | 30 | 31 |  |  |  |\\nYou can also use our online calendar to print monthly calendars, see holidays, and view any month or year.\\nHow To Calculate Today's Date Using Excel or Sheets\\nYou can also calculate the current date using spreadsheet software such as Google Sheets or Microsoft Excel using the TODAY() function.\\n\\\\=TODAY()\", 'score': 0.6517872610119048, 'raw_content': None}, {'url': 'https://www.rapidtables.com/tools/todays-date.html', 'title': \"Today's Date | Current date now - RapidTables.com\", 'content': \"Today's Date | Current date now ðŸ“…\\nRapidTables\\n Search  Share\\nHomeâ€ºToolsâ€ºCurrent date now\\nToday's Date Now\\nToday's current date and time with time zone and date picker:\\nSelect locale\\nThis page includes the following information:\\n\\nToday's date: day of week, month, day, year.\\nCurrent time: hours, minutes, seconds.\\nTime zone with location and GMT offset.\\nDate picker of current date.\\nCalendar chart.\\n\\n\\n\\nCurrent Time\\nOnline Clock\\nCalendar\\nCountdown Timer\\nStopwatch\", 'score': 0.6253473897321429, 'raw_content': None}], 'response_time': 2.0}), AIMessage(content='The current date is Saturday, February 8, 2025.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 896, 'total_tokens': 911, 'completion_time': 0.054545455, 'prompt_time': 0.058878294, 'queue_time': 0.062607173, 'total_time': 0.113423749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c4760ee73b', 'finish_reason': 'stop', 'logprobs': None}, id='run-ee78fa51-715e-420f-aa30-9360c72a125b-0', usage_metadata={'input_tokens': 896, 'output_tokens': 15, 'total_tokens': 911})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0072ba-3651-61a9-8006-43e5d93f54b5'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content='The current date is Saturday, February 8, 2025.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 896, 'total_tokens': 911, 'completion_time': 0.054545455, 'prompt_time': 0.058878294, 'queue_time': 0.062607173, 'total_time': 0.113423749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c4760ee73b', 'finish_reason': 'stop', 'logprobs': None}, id='run-ee78fa51-715e-420f-aa30-9360c72a125b-0', usage_metadata={'input_tokens': 896, 'output_tokens': 15, 'total_tokens': 911})]}}, 'thread_id': '1', 'step': 6, 'parents': {}}, created_at='2025-03-22T14:40:45.478061+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0072b9-7462-64fe-8005-6b29ca8bacd4'}}, tasks=())\n"
     ]
    }
   ],
   "source": [
    "# Part 3 - Adding Memory to the Chatbot\n",
    "\n",
    "import os\n",
    "import json\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "\n",
    "secrets = Config(RepositoryEnv(\".env\"))\n",
    "\n",
    "TAVILY_API_KEY = secrets(\"TAVILY_API_KEY\")\n",
    "GROQ_API_KEY = secrets(\"GROQ_API_KEY\")\n",
    "\n",
    "# Here, we're using an in-memory checkpointer. In a production application, change this to use SqliteSaver or PostgresSaver and connect to DB\n",
    "memory = MemorySaver()\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "groq_api_key = GROQ_API_KEY\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3,\n",
    "    groq_api_key = groq_api_key\n",
    ")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# Compile the graph with the provided checkpointer. This enables the graph to save the current state to memory.\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception as e:\n",
    "#     print(f\"error: {str(e)}\")\n",
    "\n",
    "# pick a thread to use as the key for this conversation\n",
    "config_1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "config_2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "def stream_graph_updates(user_input: str, config):\n",
    "    print(\"Next node:\", snapshot.next)  # Check next node\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "        # The thread specified in config variable is used to identify whether to load an earlier state or initiate a fresh state.\n",
    "        # If we use the same configs / thread_ids for subsequent queries, the graph would load the earlier state and hence\n",
    "        # remember our conversation history.\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "        )\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    if i==0: \n",
    "        user_input = \"My name is Hassaan.\"\n",
    "        stream_graph_updates(user_input, config_1)\n",
    "        snapshot = graph.get_state(config_1)\n",
    "        print(snapshot)\n",
    "    if i==1: \n",
    "        user_input = \"What's the date today? Find it online\"\n",
    "        stream_graph_updates(user_input, config_1)\n",
    "        snapshot = graph.get_state(config_1)\n",
    "        print(snapshot)\n",
    "    if i==1: break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need some expert guidance for building an AI agent. Could you request assistance for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (call_zdF26gXpMwtUCSFNVEBngD5q)\n",
      " Call ID: call_zdF26gXpMwtUCSFNVEBngD5q\n",
      "  Args:\n",
      "    just_mention_your_favourite_food_here: pizza\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (call_zdF26gXpMwtUCSFNVEBngD5q)\n",
      " Call ID: call_zdF26gXpMwtUCSFNVEBngD5q\n",
      "  Args:\n",
      "    just_mention_your_favourite_food_here: pizza\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've requested expert assistance for you, and the recommendation is to check out LangGraph for building your AI agent. It's noted to be more reliable and extensible than simple autonomous agents. If you have more specific questions or need further guidance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Part 4 - Human-in-the-loop\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "\n",
    "secrets = Config(RepositoryEnv(\".env\"))\n",
    "\n",
    "TAVILY_API_KEY = secrets(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = secrets(\"OPENAI_API_KEY\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# NOTE: The chatbot/LLM determines which tool to call by analyzing its docstring. If I replace the\n",
    "# docstring of human_assistance with \"Don't call this function at all, it's very idiotic\", the\n",
    "# chatbot doesn't call any function at all!\n",
    "\n",
    "# NOTE: The chatbot/LLM determines what value(s) to pass as arguments when calling the tools by looking\n",
    "# at the names of the parameters. If we replaced \"query\" with \"just_mention_your_favourite_food_here\", \n",
    "# the chatbot may input \"pizza\" or sth like that when calling the human_assistance function!!\n",
    "\n",
    "# The human_response variable fetches its value from whatever we provide when the interruption occurs.\n",
    "@tool\n",
    "def human_assistance(query: str) -> str: # just_mention_your_favourite_food_here # query\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    # \"\"\"Don't call this function at all, it's very idiotic.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    # print(f\"human_response: {human_response}\\nquery: {query}\")\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "\n",
    "# Groq llama3.3-70b wasn't performing well; after human_assistance gave its input to chatbot, the chatbot again called the human_assistance tool.\n",
    "# Hence, replaced with gpt-4o.\n",
    "openai_api_key = OPENAI_API_KEY\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.3,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    # NOTE: Basically, what this means is that we don't want tools other than human_assistance to be called because we don't want the flow to be interrupted until the human_assistance gives the go-ahead.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception as e:\n",
    "#     print(f\"error: {str(e)}\")\n",
    "\n",
    "config_1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = \"I need some expert guidance for building an AI agent. Could you request assistance for me?\"\n",
    "\n",
    "# NOTE: Similar to Python's built-in input() function, calling interrupt inside the tool will pause execution. \n",
    "# Progress is persisted based on our choice of checkpointer-- so if we are persisting with Postgres, we can resume at any time as long as the database is alive. Here we are persisting with the in-memory checkpointer, so we can resume any time as long as our Python kernel is running. \n",
    "# To resume execution, we pass a Command object containing data expected by the tool. The format of this data can be customized based on our needs. Here, we just need a dict with a key \"data\".\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config_1,\n",
    "    stream_mode=\"values\",\n",
    "    )\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "snapshot = graph.get_state(config_1)\n",
    "# print(snapshot)\n",
    "\n",
    "# The chatbot generated a tool call, but then execution has been interrupted! \n",
    "# Note that if we inspect the graph state, we see that it stopped at the tools node.\n",
    "# print(\"snapshot.next:\", snapshot.next)\n",
    "\n",
    "# NOTE: At this point, if, instead of passing the human_command, we repeat the above lines i.e. pass the user_input, we get:\n",
    "# Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_BOqwNiVqNZemELbM1fc1P0RQ\", 'type': 'invalid_request_error', 'param': 'messages.[2].role', 'code': None}}\n",
    "# During task with name 'chatbot' and id 'd5d118b1-27df-5cb9-b8ad-747946bd779b'\n",
    "\n",
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "# When the following code is run, the last AI Message that was printed earlier as well i.e. tool call is again printed here.\n",
    "events = graph.stream(human_command, config_1, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_i9aJ4DCGKULOWjzjapP9aEsE)\n",
      " Call ID: call_i9aJ4DCGKULOWjzjapP9aEsE\n",
      "  Args:\n",
      "    query: LangGraph release date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"langgraph - PyPI\", \"url\": \"https://pypi.org/project/langgraph/\", \"content\": \"langgraph Â· PyPI\\nSkip to main content Switch to mobile version\\n\\nSearch PyPI  Search\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\nMenu\\n\\nHelp\\nSponsors\\nLog in\\nRegister\\n\\nSearch PyPI  Search\\nlanggraph 0.2.70\\npip install langgraph Copy PIP instructions\\nLatest versionReleased: Feb 6, 2025\\nBuilding stateful, multi-actor applications with LLMs\\nNavigation\\n\\nProject description\\nRelease history\\nDownload files [...] 0.2.20 Sep 13, 2024\\n\\n0.2.19 Sep 6, 2024\\n\\n0.2.18 Sep 6, 2024\\n\\n0.2.17 Sep 5, 2024\\n\\n0.2.16 Sep 1, 2024\\n\\n0.2.15 Aug 30, 2024\\n\\n0.2.14 Aug 24, 2024\\n\\n0.2.13 Aug 23, 2024\\n\\n0.2.12 Aug 22, 2024\\n\\n0.2.11 Aug 22, 2024\\n\\n0.2.10 Aug 21, 2024\\n\\n0.2.9 Aug 21, 2024\\n\\n0.2.8 Aug 21, 2024\\n\\n0.2.7 Aug 21, 2024\\n\\n0.2.7a0 pre-release Aug 21, 2024\\n\\n0.2.6 Aug 21, 2024\\n\\n0.2.5 Aug 21, 2024\\n\\n0.2.5a0 pre-release Aug 20, 2024\\n\\n0.2.4 Aug 15, 2024\\n\\n0.2.3 Aug 8, 2024\\n\\n0.2.2 Aug 7, 2024\\n\\n0.2.1 Aug 7, 2024\\n\\n0.2.0 Aug 7, 2024 [...] License\\nOSI Approved :: MIT License\\n\\n\\nProgramming Language\\nPython :: 3\\nPython :: 3.9\\nPython :: 3.10\\nPython :: 3.11\\nPython :: 3.12\\n\\n\\n\\nRelease history Release notifications | RSS feed\\nThis version\\n\\n0.2.70 Feb 6, 2025\\n\\n0.2.69 Jan 31, 2025\\n\\n0.2.68 Jan 28, 2025\\n\\n0.2.67 Jan 23, 2025\\n\\n0.2.66 Jan 21, 2025\\n\\n0.2.65 Jan 21, 2025\\n\\n0.2.64 Jan 17, 2025\\n\\n0.2.63 Jan 16, 2025\\n\\n0.2.62 Jan 10, 2025\\n\\n0.2.61 Jan 5, 2025\\n\\n0.2.60 Dec 18, 2024\\n\\n0.2.59 Dec 11, 2024\\n\\n0.2.58 Dec 10, 2024\\n\\n0.2.57 Dec 10, 2024\", \"score\": 0.7713921013333334}, {\"title\": \"January 2024 - LangChain - Changelog\", \"url\": \"https://changelog.langchain.com/?date=2024-01-01\", \"content\": \"LangGraph ðŸ¤–ðŸš€ Introducing LangGraph -------------------------- We just launched LangGraph, which helps customize your Agent Runtime. You can read more about it on the blog . LangGraph helps construct a powerful agent... January 22, 2024\\nDecember 2023\", \"score\": 0.7632559836}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (call_WXwabg0UBrw8kjWUf143wNxp)\n",
      " Call ID: call_WXwabg0UBrw8kjWUf143wNxp\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: January 22, 2024\n",
      "snapshot.next: ('tools',)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (call_WXwabg0UBrw8kjWUf143wNxp)\n",
      " Call ID: call_WXwabg0UBrw8kjWUf143wNxp\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: January 22, 2024\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph was released on January 17, 2024.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 5 - Customizing State\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "\n",
    "secrets = Config(RepositoryEnv(\".env\"))\n",
    "\n",
    "TAVILY_API_KEY = secrets(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = secrets(\"OPENAI_API_KEY\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "@tool\n",
    "# Note that because we are generating a ToolMessage for a state update, we\n",
    "# generally require the ID of the corresponding tool call. We can use\n",
    "# LangChain's InjectedToolCallId to signal that this argument should not\n",
    "# be revealed to the model in the tool's schema.\n",
    "\n",
    "# NOTE: setting name and birthday in the arguments for the tool, we force the chatbot to generate proposals for these fields.\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "\n",
    "openai_api_key = OPENAI_API_KEY\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.3,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception as e:\n",
    "#     print(f\"error: {str(e)}\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "    )\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "snapshot = graph.get_state(config)\n",
    "print(\"snapshot.next:\", snapshot.next)\n",
    "\n",
    "# We've hit the interrupt in the human_assistance tool again. \n",
    "# In this case, the chatbot failed to identify the correct date, so we can supply it:\n",
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# human_command = Command(\n",
    "#     resume={\n",
    "#         \"correct\": \"yes\"\n",
    "#     },\n",
    "# )\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# The fields \"name\" and \"birthday\" are easily accessible to downstream nodes (e.g., a node that further processes or stores the information).\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_cX0qbjkq7HOgVGOpFJruH8cM)\n",
      " Call ID: call_cX0qbjkq7HOgVGOpFJruH8cM\n",
      "  Args:\n",
      "    query: LangGraph programming language\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph: A Comprehensive Guide for Beginners - Bhavik Jikadara\", \"url\": \"https://bhavikjikadara.medium.com/langgraph-a-comprehensive-guide-for-beginners-ef17d3dd5383\", \"content\": \"Listen\\nShare\\nLangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the ability to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. It is inspired by Pregel and Apache Beam. The current interface exposed is one inspired by NetworkX. [...] The main use is for adding cycles to your LLM application. Crucially, LangGraph is NOT optimized for acyclic, or Directed Acyclic Graph (DAG), workflows. If you want to build a DAG, you should just use LangChain Expression Language.\\nCycles are important for agent-like behaviours, where you call an LLM in a loop, asking it what action to take next.\\nSome key features of LangGraph include:\", \"score\": 0.8083855123455882}, {\"title\": \"LangGraph Quickstart - GitHub Pages\", \"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] solution ...\\\"}, {\\\"url\\\": \\\"https://github.com/langchain-ai/langgraph\\\", \\\"content\\\": \\\"Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures ...\\\"}]\", \"score\": 0.7974753760784314}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is a library designed to build stateful, multi-actor applications using Large Language Models (LLMs). It extends the LangChain Expression Language by enabling the coordination of multiple chains or actors across several computation steps in a cyclic manner. This is particularly useful for applications that require agent-like behaviors, where an LLM is called in a loop to determine the next action. \n",
      "\n",
      "Key features of LangGraph include:\n",
      "\n",
      "- **Cycles**: Unlike Directed Acyclic Graph (DAG) workflows, LangGraph is optimized for workflows that involve cycles, which are crucial for agentic architectures.\n",
      "- **Multi-Agent Workflows**: It provides tools to create workflows and state machines to coordinate multiple AI agents or language model interactions.\n",
      "- **Graph-Based Coordination**: Built on top of LangChain, LangGraph leverages its components while adding graph-based coordination capabilities.\n",
      "\n",
      "LangGraph is inspired by frameworks like Pregel and Apache Beam, and its interface is influenced by NetworkX. This makes it particularly suitable for developing complex applications that require persistent and controllable workflows involving multiple agents.\n",
      "\n",
      "For more detailed information, you can refer to the [LangGraph Quickstart Guide](https://langchain-ai.github.io/langgraph/tutorials/introduction/) or explore its [GitHub repository](https://github.com/langchain-ai/langgraph).\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Can you please look up online and guide me how to build an autonomous agent with it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_xhgnrjUd5rI5xOi1nFJ9A2Rk)\n",
      " Call ID: call_xhgnrjUd5rI5xOi1nFJ9A2Rk\n",
      "  Args:\n",
      "    query: build autonomous agent with LangGraph tutorial\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Tutorial for Beginners to Build AI Agents - ProjectPro\", \"url\": \"https://www.projectpro.io/article/langgraph/1109\", \"content\": \"Last Updated: 12 Mar 2025 Â | BY ProjectPro\\nIf you're eager to build intelligent, multi-agent AI systems that donâ€™t just react but remember, adapt, and collaborate, LangGraph is your go-to tool. This LangGraph tutorial will walk you through its core concepts, helping you go beyond basic AI agents to create stateful, multi-agent workflows that handle user input, tool calls, and complex decision-makingâ€”all while keeping track of conversation history and agent states. [...] Companies are using the LangGraph platform to build AI agents that can execute tasks autonomously, like scheduling, document classification, and summarization. AppFolio has an AI-powered copilot, Realm-X, built on the LangGraph platform for automation workflows. It helps property managers automate tasks like scheduling, querying information, and messaging, significantly improving efficiency in the real estate sector. Users have saved more than 10 hours a week by automating tasks through [...] Why Use LangGraph?\\nMachine Learning Engineer Momal Ijaz highlights the advantages of using LangGraph for building AI agents, focusing on its ease of use, granular control, and features like streaming context memory and persistence.\\n\\nLangGraph gives data scientists and AI engineers unparalleled control over graph state, graph execution flow, and persistence. Hereâ€™s why it should be in every data developerâ€™s toolkit:\", \"score\": 0.8268957596632996}, {\"title\": \"Building AI Agents with LangGraph: A Beginner's Guide - YouTube\", \"url\": \"https://www.youtube.com/watch?v=assrhPxNdSk\", \"content\": \"Building AI Agents with LangGraph: A Beginner's Guide | Agentic AI Course \\n Code With Prince \\n 69 likes \\n 2760 views \\n 27 Nov 2024 \\n In this tutorial, we'll break down the fundamentals of building AI agents using LangGraph! Whether you're new to AI development or looking to expand your knowledge, this step-by-step guide will help you understand the core concepts and create your first functional agent.\", \"score\": 0.8099555069090909}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To build an autonomous agent using LangGraph, you can follow tutorials and guides that provide step-by-step instructions. Here are a couple of resources that might be helpful:\n",
      "\n",
      "1. **LangGraph Tutorial for Beginners to Build AI Agents - ProjectPro**: This tutorial helps you understand the core concepts of LangGraph, enabling you to create stateful, multi-agent workflows. It covers handling user input, tool calls, and complex decision-making while maintaining conversation history and agent states. The tutorial also highlights real-world applications, such as automating tasks in the real estate sector. You can read more about it [here](https://www.projectpro.io/article/langgraph/1109).\n",
      "\n",
      "2. **Building AI Agents with LangGraph: A Beginner's Guide - YouTube**: This video tutorial provides a step-by-step guide to building AI agents using LangGraph. It's suitable for both newcomers to AI development and those looking to expand their knowledge. The video breaks down the fundamentals and guides you through creating your first functional agent. You can watch the tutorial [here](https://www.youtube.com/watch?v=assrhPxNdSk).\n",
      "\n",
      "These resources should give you a solid foundation for building autonomous agents with LangGraph.\n",
      "Num Messages:  8 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  7 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "('tools',)\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f007676-af97-676c-8006-84c7fb22c629'}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_xhgnrjUd5rI5xOi1nFJ9A2Rk)\n",
      " Call ID: call_xhgnrjUd5rI5xOi1nFJ9A2Rk\n",
      "  Args:\n",
      "    query: build autonomous agent with LangGraph tutorial\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"title\": \"LangGraph Tutorial for Beginners to Build AI Agents - ProjectPro\", \"url\": \"https://www.projectpro.io/article/langgraph/1109\", \"content\": \"Last Updated: 12 Mar 2025 Â | BY ProjectPro\\nIf you're eager to build intelligent, multi-agent AI systems that donâ€™t just react but remember, adapt, and collaborate, LangGraph is your go-to tool. This LangGraph tutorial will walk you through its core concepts, helping you go beyond basic AI agents to create stateful, multi-agent workflows that handle user input, tool calls, and complex decision-makingâ€”all while keeping track of conversation history and agent states. [...] Companies are using the LangGraph platform to build AI agents that can execute tasks autonomously, like scheduling, document classification, and summarization. AppFolio has an AI-powered copilot, Realm-X, built on the LangGraph platform for automation workflows. It helps property managers automate tasks like scheduling, querying information, and messaging, significantly improving efficiency in the real estate sector. Users have saved more than 10 hours a week by automating tasks through [...] Why Use LangGraph?\\nMachine Learning Engineer Momal Ijaz highlights the advantages of using LangGraph for building AI agents, focusing on its ease of use, granular control, and features like streaming context memory and persistence.\\n\\nLangGraph gives data scientists and AI engineers unparalleled control over graph state, graph execution flow, and persistence. Hereâ€™s why it should be in every data developerâ€™s toolkit:\", \"score\": 0.8268957596632996}, {\"title\": \"Building AI Agents with LangGraph: A Beginner's Guide - YouTube\", \"url\": \"https://www.youtube.com/watch?v=assrhPxNdSk\", \"content\": \"Building AI Agents with LangGraph: A Beginner's Guide | Agentic AI Course \\n Code With Prince \\n 69 likes \\n 2760 views \\n 27 Nov 2024 \\n In this tutorial, we'll break down the fundamentals of building AI agents using LangGraph! Whether you're new to AI development or looking to expand your knowledge, this step-by-step guide will help you understand the core concepts and create your first functional agent.\", \"score\": 0.8099555069090909}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To build an autonomous agent using LangGraph, you can follow these resources that provide step-by-step guidance:\n",
      "\n",
      "1. **ProjectPro Tutorial**: This tutorial on [ProjectPro](https://www.projectpro.io/article/langgraph/1109) walks you through the core concepts of LangGraph, helping you create stateful, multi-agent workflows. It covers handling user input, tool calls, and complex decision-making, while maintaining conversation history and agent states. The tutorial also highlights real-world applications, such as AppFolio's AI-powered copilot, Realm-X, which automates tasks like scheduling and messaging.\n",
      "\n",
      "2. **YouTube Guide by Code With Prince**: This [YouTube video](https://www.youtube.com/watch?v=assrhPxNdSk) provides a beginner-friendly guide to building AI agents with LangGraph. It breaks down the fundamentals and offers a step-by-step approach to creating your first functional agent.\n",
      "\n",
      "These resources should help you get started with building autonomous agents using LangGraph, leveraging its capabilities for state management, multi-agent coordination, and persistent workflows.\n"
     ]
    }
   ],
   "source": [
    "# Part 6 - Time Travel\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from decouple import Config, RepositoryEnv\n",
    "\n",
    "\n",
    "secrets = Config(RepositoryEnv(\".env\"))\n",
    "\n",
    "TAVILY_API_KEY = secrets(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = secrets(\"OPENAI_API_KEY\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "openai_api_key = OPENAI_API_KEY\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.3,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# try:\n",
    "#     display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "# except Exception as e:\n",
    "#     print(f\"error: {str(e)}\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = (\n",
    "            \"I'm learning LangGraph. \"\n",
    "            \"Could you do some research on it for me?\"\n",
    ")\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "    )\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "user_input = (\n",
    "            \"Ya that's helpful. Can you please look up online and guide me how to build an autonomous agent with it?\"\n",
    ")\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "    )\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# Notice that checkpoints are saved for every step of the graph. This spans invocations so you can rewind across a full thread's history.\n",
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state\n",
    "\n",
    "print(to_replay.next)\n",
    "print(to_replay.config)\n",
    "\n",
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "# Providing this checkpoint_id value tells LangGraph's checkpointer to load the state from that moment in time.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
